{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# remove misformatted row due to bad html\n",
    "raw_df = (\n",
    "    pd.read_csv('data/raw/quakenu_raw.csv')\n",
    "        .drop(16803, axis=0)\n",
    ")\n",
    "\n",
    "# Use 3 decimal places in output display\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "# Set max rows displayed in output to 25\n",
    "pd.set_option(\"display.max_rows\", 25)\n",
    "# print(raw_df[:1])\n",
    "# print(raw_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BYRONA~1\\AppData\\Local\\Temp/ipykernel_6756/1649249616.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['date'] = pd.to_datetime(clean_df['date'], format='%Y-%m-%d, %H:%M')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "cleaning_test_df = raw_df[::1000] # every 1000th post\n",
    "\n",
    "def clean_post_df(raw_df):\n",
    "    clean_df = raw_df\n",
    "    clean_df['date'] = pd.to_datetime(clean_df['date'], format='%Y-%m-%d, %H:%M')\n",
    "    return clean_df\n",
    "\n",
    "clean_test_df = clean_post_df(cleaning_test_df)\n",
    "clean_df = clean_post_df(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BYRONA~1\\AppData\\Local\\Temp/ipykernel_6756/2140873254.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  raw_text_col = raw_df['post_text'].str.replace('[^\\w\\']', ' ', flags=re.UNICODE)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "raw_text_col = raw_df['post_text'].str.replace('[^\\w\\']', ' ', flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(raw_df.columns)\n",
    "OLD_MEMBER_CUTOFF = 50\n",
    "MIN_POST_CUTOFF = 5\n",
    "\n",
    "min_post_df = clean_df.groupby('author').filter(lambda group : len(group) > MIN_POST_CUTOFF)\n",
    "\n",
    "forum_first_post_dt = min_post_df['date'].min()\n",
    "forum_time_range = min_post_df['date'].max() - forum_first_post_dt\n",
    "# print(forum_time_range)\n",
    "\n",
    "author_groups = min_post_df.groupby('author')\n",
    "last_post_dt = author_groups['date'].max()\n",
    "first_post_dt = author_groups['date'].min()\n",
    "post_time_range = last_post_dt - first_post_dt\n",
    "last_post_era = (last_post_dt - forum_first_post_dt) / forum_time_range\n",
    "\n",
    "# print(last_post_era)\n",
    "\n",
    "post_frequency_seconds = post_time_range.dt.total_seconds() / author_groups['date'].count()\n",
    "median_post_freq = author_groups['date'].agg(\n",
    "    lambda group: group.sort_values().diff().median()\n",
    ").dt.total_seconds()\n",
    "is_old_member = author_groups['date'].count() > OLD_MEMBER_CUTOFF\n",
    "\n",
    "median_post_length_chars = min_post_df['post_text'].str.len().dropna().groupby(min_post_df['author']).median()\n",
    "\n",
    "# print(sum(is_old_member))\n",
    "# print(raw_df[raw_df['post_text'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "0        3.045e+06\n",
      "1        1.524e+04\n",
      "100      5.831e+06\n",
      "1000     4.146e+04\n",
      "10002    2.692e+06\n",
      "           ...    \n",
      "9978     3.657e+04\n",
      "9981     8.256e+04\n",
      "9993     1.800e+02\n",
      "9995     1.230e+04\n",
      "9996     8.148e+04\n",
      "Name: date, Length: 1283, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "post_counts = author_groups['date'].agg(\n",
    "    lambda group: group.count() # group.sort_values().diff().count()\n",
    ")\n",
    "\n",
    "sum(post_counts > 2)\n",
    "\n",
    "print(median_post_freq.dt.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix \n",
    "\n",
    "# X = pd.concat([post_frequency_seconds, last_post_era], axis=1, keys=['post_freq', 'post_era'])\n",
    "X = pd.concat([median_post_freq, last_post_era, median_post_length_chars], axis=1, keys=['post_freq', 'post_era', 'post_len'])\n",
    "X['post_len'].fillna(X['post_len'].median(), inplace=True)\n",
    "y = is_old_member\n",
    "\n",
    "np.random.seed(3342)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "old_member_pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('classifier', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_member_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.90      0.84       154\n",
      "        True       0.64      0.42      0.50        65\n",
      "\n",
      "    accuracy                           0.76       219\n",
      "   macro avg       0.71      0.66      0.67       219\n",
      "weighted avg       0.74      0.76      0.74       219\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.90      0.85       465\n",
      "        True       0.65      0.45      0.53       190\n",
      "\n",
      "    accuracy                           0.77       655\n",
      "   macro avg       0.73      0.68      0.69       655\n",
      "weighted avg       0.76      0.77      0.76       655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = old_member_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))\n",
    "\n",
    "y_hat_train = old_member_pipeline.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "3       270.997\n",
      "122     106.881\n",
      "6       154.400\n",
      "1       305.435\n",
      "47      184.000\n",
      "         ...   \n",
      "2519    347.333\n",
      "3415    157.000\n",
      "3533    414.000\n",
      "3395     67.000\n",
      "2533    835.500\n",
      "Name: post_text, Length: 2105, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(raw_df['post_text'].str.len().groupby(raw_df['author'], sort=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       thread post_id  \\\n",
      "71009      52   13465   \n",
      "12233    1603   81343   \n",
      "40107    3717   46730   \n",
      "78437     104   31865   \n",
      "58465    6990  105734   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                post_text  \n",
      "71009   now look at this: d2 vs zoo dm2 179:182 - we lose 1:2 instead of 2:0 win d2 vs ls e1m2 190:223 (one of our players timeouted when we had map under control) - we lose 1:2 instead of 2:0 win d2 vs mny dm3 138:153 - we lose 1:2 instead of 2:0 win d2 vs tot dm3 145:147 - we win only 2:1 instead of 2:0  d2 vs freedom dm3 154:188 - we lose 1:2 instead of 2:0 win 1 + 1 + 1 + 2 + 1 = 6 points <- this is what we've got 3 + 3 + 3 + 3 + 3 = 15 points <- this is what we would have if we had a bit more luck  so please don't tell me more about close games  . it's part of the game. but i can see flaws in your logic. you bring 'close games' argument but only when it comes to close map scores. but what about close _games_, i mean 2:1 or 1:2 is close, 2:0 is not. if you really want to reward team who mostly loses games but every game of that team is close then the current system is just doing it  . this way team who won 3 games 2:1 and lost 7 games 1:2 (13 points) still have chances for better place than team who won 6 games 2:1 but lost 4 games 0:2 (12 points) if you know what i mean. that doesn't change my mind of course, i prefer 3 points for 2:1. winning map with 1 frag is in the same price as winning it 400:10 so why is 2:1 win worse than 2:0 win. quake shall be brutal  . too much for who?  \n",
      "12233                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                nice phil   is that an outdoor meal? or did you warm it up yourself?  \n",
      "40107                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     spectator mode.  \n",
      "78437                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      please do not compress the .pk3 that you bundle the textures into, i presume you are using winzip or something with default options, but this compression increases loading times massively for a mere 130m reduction in filesystem usage (you will still save on download size because you already place the .pk3 within another .zip for download!) 198m 2007-10-06 10:56 qrp-maptextures-2007-10-06r2.pk3 333m 2007-11-08 13:11 qrp-maptextures-2007-10-06r2-uncompressed.pk3 $ unzip -d /tmp/qrp qrp-maptextures-2007-10-06r2.pk3 $ pushd /tmp/qrp $ zip -0r qrp-maptextures-2007-10-06r2-uncompressed.pk3 textures $ popd  \n",
      "58465                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                i guess canadians aren't invited. i see how it is...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Text gathering/cleaning issues\n",
    "    - scraper not catching underlines, italics, etc https://www.quakeworld.nu/forum/topic/28\n",
    "    - bb-code divs https://www.quakeworld.nu/forum/topic/28\n",
    "    - \n",
    "\"\"\"\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\"\"\"\n",
    "Cleaning a single string for NLP\n",
    "    \n",
    "    - remove nonchars except for apostrophes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(raw_df[['thread', 'post_id', 'post_text']].sample(n=5))\n",
    "# print(raw_text_col.sample(n=5))\n",
    "# print([text for text in raw_text_col.sample(n=15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si senor, ?que necesita?\n",
      "I\n",
      "guess\n",
      "canadian\n",
      "be\n",
      "not\n",
      "invite\n",
      ".\n",
      "I\n",
      "see\n",
      "how\n",
      "it\n",
      "be\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "test_accent_str = \"Sí señor, ¿qué necesita?\"\n",
    "\n",
    "print(unidecode.unidecode(test_accent_str))\n",
    "\n",
    "test_lemma_str = \"i guess canadians aren't invited. i see how it is...\"\n",
    "\n",
    "test_lemma_doc = nlp(test_lemma_str)\n",
    "\n",
    "for token in test_lemma_doc:\n",
    "    print(token.lemma_)\n",
    "    # print(token.is_sent_start)\n",
    "\n",
    "# print(' '.join([token.lemma_ for token in test_lemma_doc]))\n",
    "# print(test_lemma_doc.cats)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75f4a77460bc6a4b29b28071ea1801e9a6c8562880a5c01318289c3ebdc5420b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('scraping': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
